{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Texto con MoE - Análisis Avanzado\n",
    "\n",
    "Este notebook demuestra las capacidades avanzadas del MoE para procesamiento de texto, incluyendo análisis detallado de tokens y visualización de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from text_processing.text_moe import TextMoE\n",
    "from utils.dashboard import ComplexityDashboard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuración y Análisis Inicial\n",
    "\n",
    "Configuramos el TextMoE y analizamos su comportamiento con diferentes tipos de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "text_moe = TextMoE(num_experts=3)\n",
    "dashboard = ComplexityDashboard()\n",
    "\n",
    "# Conjunto diverso de textos para análisis\n",
    "textos = [\n",
    "    \"The quick brown fox jumps\",  # Mezcla de longitudes\n",
    "    \"AI ML NLP deep learning\",    # Términos técnicos\n",
    "    \"a an the but or and\",        # Palabras cortas\n",
    "    \"extraordinary sophisticated\" # Palabras largas\n",
    "]\n",
    "\n",
    "# Procesar y analizar cada texto\n",
    "resultados = []\n",
    "for texto in textos:\n",
    "    print(f\"\\nProcesando: {texto}\")\n",
    "    resultado = text_moe.process(texto)\n",
    "    print(resultado)\n",
    "    \n",
    "    # Recolectar métricas para visualización\n",
    "    tokens = texto.split()\n",
    "    for token in tokens:\n",
    "        complejidad = text_moe._compute_complexity(token)\n",
    "        resultados.append({\n",
    "            'token': token,\n",
    "            'complejidad': complejidad,\n",
    "            'longitud': len(token)\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualización de Métricas\n",
    "\n",
    "Analizamos la distribución de complejidad y la relación con la longitud de los tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualizar_metricas(resultados):\n",
    "    complejidades = [r['complejidad'] for r in resultados]\n",
    "    longitudes = [r['longitud'] for r in resultados]\n",
    "    tokens = [r['token'] for r in resultados]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Distribución de complejidad\n",
    "    ax1.hist(complejidades, bins=15, color='skyblue', alpha=0.7)\n",
    "    ax1.set_title('Distribución de Complejidad')\n",
    "    ax1.set_xlabel('Complejidad')\n",
    "    ax1.set_ylabel('Frecuencia')\n",
    "    \n",
    "    # Relación longitud vs complejidad\n",
    "    scatter = ax2.scatter(longitudes, complejidades, \n",
    "                         c=complejidades, cmap='viridis', \n",
    "                         alpha=0.6)\n",
    "    ax2.set_title('Longitud vs Complejidad')\n",
    "    ax2.set_xlabel('Longitud del Token')\n",
    "    ax2.set_ylabel('Complejidad')\n",
    "    plt.colorbar(scatter, ax=ax2, label='Complejidad')\n",
    "    \n",
    "    # Añadir etiquetas para algunos puntos interesantes\n",
    "    for i, token in enumerate(tokens):\n",
    "        if resultados[i]['complejidad'] > np.mean(complejidades) + np.std(complejidades):\n",
    "            ax2.annotate(token, \n",
    "                        (longitudes[i], complejidades[i]),\n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar estadísticas\n",
    "    print(\"\\nEstadísticas de complejidad:\")\n",
    "    print(f\"Media: {np.mean(complejidades):.2f}\")\n",
    "    print(f\"Desviación estándar: {np.std(complejidades):.2f}\")\n",
    "    print(f\"Máxima: {np.max(complejidades):.2f} ({tokens[np.argmax(complejidades)]})\")\n",
    "    print(f\"Mínima: {np.min(complejidades):.2f} ({tokens[np.argmin(complejidades)]})\")\n",
    "\n",
    "visualizar_metricas(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis de Patrones\n",
    "\n",
    "Analizamos los patrones de asignación de expertos en un texto más largo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "texto_largo = \"\"\"\n",
    "Natural Language Processing (NLP) combines linguistics and artificial intelligence \n",
    "to enable computers to process, understand, and generate human language effectively.\n",
    "\"\"\"\n",
    "\n",
    "def analizar_asignaciones(texto):\n",
    "    tokens = texto.split()\n",
    "    asignaciones = []\n",
    "    complejidades = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        complejidad = text_moe._compute_complexity(token)\n",
    "        expert_weights = text_moe._get_expert_weights(token)\n",
    "        experto = np.argmax(expert_weights)\n",
    "        \n",
    "        asignaciones.append(experto)\n",
    "        complejidades.append(complejidad)\n",
    "        \n",
    "        # Actualizar dashboard\n",
    "        dashboard.update_metrics('text_complexity', complejidad)\n",
    "        dashboard.update_metrics('expert_assignment', experto)\n",
    "    \n",
    "    return tokens, asignaciones, complejidades\n",
    "\n",
    "tokens, asignaciones, complejidades = analizar_asignaciones(texto_largo)\n",
    "\n",
    "# Visualizar distribución de expertos\n",
    "expert_counts = np.bincount(asignaciones)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(len(expert_counts)), expert_counts)\n",
    "plt.title('Distribución de Asignaciones por Experto')\n",
    "plt.xlabel('Experto ID')\n",
    "plt.ylabel('Número de Tokens')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar asignaciones detalladas\n",
    "print(\"\\nAsignaciones detalladas:\")\n",
    "for token, experto, comp in zip(tokens, asignaciones, complejidades):\n",
    "    print(f\"Token: {token:15} | Experto: {experto} | Complejidad: {comp:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monitoreo en Tiempo Real\n",
    "\n",
    "Simulamos procesamiento continuo y monitoreamos en tiempo real usando el dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "def generar_token_aleatorio(min_len=1, max_len=15):\n",
    "    length = random.randint(min_len, max_len)\n",
    "    chars = string.ascii_letters + string.digits + string.punctuation\n",
    "    return ''.join(random.choice(chars) for _ in range(length))\n",
    "\n",
    "def simular_procesamiento(num_tokens=50):\n",
    "    for _ in range(num_tokens):\n",
    "        token = generar_token_aleatorio()\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Procesar token\n",
    "        complejidad = text_moe._compute_complexity(token)\n",
    "        expert_weights = text_moe._get_expert_weights(token)\n",
    "        experto = np.argmax(expert_weights)\n",
    "        \n",
    "        # Calcular tiempo de procesamiento\n",
    "        tiempo = time.perf_counter() - start_time\n",
    "        \n",
    "        # Actualizar dashboard\n",
    "        dashboard.update_metrics('text_complexity', complejidad)\n",
    "        dashboard.update_metrics('expert_assignment', experto)\n",
    "        dashboard.update_metrics('processing_time', tiempo)\n",
    "        \n",
    "        time.sleep(0.1)  # Pausa para visualización\n",
    "\n",
    "# Iniciar simulación y mostrar dashboard\n",
    "print(\"Iniciando simulación de procesamiento...\")\n",
    "simular_procesamiento()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}